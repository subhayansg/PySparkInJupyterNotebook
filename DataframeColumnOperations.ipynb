{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b255d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Processing Column Data'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b92a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf0acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "orders = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"path\", \"/public/retail_db/orders\") \\\n",
    "    .schema('order_id INT, order_date STRING, order_customer_id INT, order_status STRING') \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c0fdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------------+---------------+\n",
      "|order_id|order_date           |order_customer_id|order_status   |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "|1       |2013-07-25 00:00:00.0|11599            |CLOSED         |\n",
      "|2       |2013-07-25 00:00:00.0|256              |PENDING_PAYMENT|\n",
      "|3       |2013-07-25 00:00:00.0|12111            |COMPLETE       |\n",
      "|4       |2013-07-25 00:00:00.0|8827             |CLOSED         |\n",
      "|5       |2013-07-25 00:00:00.0|11318            |COMPLETE       |\n",
      "|6       |2013-07-25 00:00:00.0|7130             |COMPLETE       |\n",
      "|7       |2013-07-25 00:00:00.0|4530             |COMPLETE       |\n",
      "|8       |2013-07-25 00:00:00.0|2911             |PROCESSING     |\n",
      "|9       |2013-07-25 00:00:00.0|5657             |PENDING_PAYMENT|\n",
      "|10      |2013-07-25 00:00:00.0|5648             |PENDING_PAYMENT|\n",
      "|11      |2013-07-25 00:00:00.0|918              |PAYMENT_REVIEW |\n",
      "|12      |2013-07-25 00:00:00.0|1837             |CLOSED         |\n",
      "|13      |2013-07-25 00:00:00.0|9149             |PENDING_PAYMENT|\n",
      "|14      |2013-07-25 00:00:00.0|9842             |PROCESSING     |\n",
      "|15      |2013-07-25 00:00:00.0|2568             |COMPLETE       |\n",
      "|16      |2013-07-25 00:00:00.0|7276             |PENDING_PAYMENT|\n",
      "|17      |2013-07-25 00:00:00.0|2667             |COMPLETE       |\n",
      "|18      |2013-07-25 00:00:00.0|1205             |CLOSED         |\n",
      "|19      |2013-07-25 00:00:00.0|9488             |PENDING_PAYMENT|\n",
      "|20      |2013-07-25 00:00:00.0|9198             |PROCESSING     |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9d56ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- order_date: string (nullable = true)\n",
      " |-- order_customer_id: integer (nullable = true)\n",
      " |-- order_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f73021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------------+---------------+-----------+\n",
      "|order_id|order_date           |order_customer_id|order_status   |order_month|\n",
      "+--------+---------------------+-----------------+---------------+-----------+\n",
      "|1       |2013-07-25 00:00:00.0|11599            |CLOSED         |Jul        |\n",
      "|2       |2013-07-25 00:00:00.0|256              |PENDING_PAYMENT|Jul        |\n",
      "|3       |2013-07-25 00:00:00.0|12111            |COMPLETE       |Jul        |\n",
      "|4       |2013-07-25 00:00:00.0|8827             |CLOSED         |Jul        |\n",
      "|5       |2013-07-25 00:00:00.0|11318            |COMPLETE       |Jul        |\n",
      "|6       |2013-07-25 00:00:00.0|7130             |COMPLETE       |Jul        |\n",
      "|7       |2013-07-25 00:00:00.0|4530             |COMPLETE       |Jul        |\n",
      "|8       |2013-07-25 00:00:00.0|2911             |PROCESSING     |Jul        |\n",
      "|9       |2013-07-25 00:00:00.0|5657             |PENDING_PAYMENT|Jul        |\n",
      "|10      |2013-07-25 00:00:00.0|5648             |PENDING_PAYMENT|Jul        |\n",
      "+--------+---------------------+-----------------+---------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a column order_month\n",
    "\n",
    "orders.select(\"*\", date_format(\"order_date\", \"MMM\").alias(\"order_month\")).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a674d18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------------+---------------+-----------+\n",
      "|order_id|order_date           |order_customer_id|order_status   |order_month|\n",
      "+--------+---------------------+-----------------+---------------+-----------+\n",
      "|1       |2013-07-25 00:00:00.0|11599            |CLOSED         |Jul        |\n",
      "|2       |2013-07-25 00:00:00.0|256              |PENDING_PAYMENT|Jul        |\n",
      "|3       |2013-07-25 00:00:00.0|12111            |COMPLETE       |Jul        |\n",
      "|4       |2013-07-25 00:00:00.0|8827             |CLOSED         |Jul        |\n",
      "|5       |2013-07-25 00:00:00.0|11318            |COMPLETE       |Jul        |\n",
      "|6       |2013-07-25 00:00:00.0|7130             |COMPLETE       |Jul        |\n",
      "|7       |2013-07-25 00:00:00.0|4530             |COMPLETE       |Jul        |\n",
      "|8       |2013-07-25 00:00:00.0|2911             |PROCESSING     |Jul        |\n",
      "|9       |2013-07-25 00:00:00.0|5657             |PENDING_PAYMENT|Jul        |\n",
      "|10      |2013-07-25 00:00:00.0|5648             |PENDING_PAYMENT|Jul        |\n",
      "+--------+---------------------+-----------------+---------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders.withColumn(\"order_month\", date_format(\"order_date\", \"MMM\")).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0276771b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------+-----------------+---------------+\n",
      "|order_id|order_date           |order_customer_id|order_status   |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "|25876   |2014-01-01 00:00:00.0|3414             |PENDING_PAYMENT|\n",
      "|25877   |2014-01-01 00:00:00.0|5549             |PENDING_PAYMENT|\n",
      "|25878   |2014-01-01 00:00:00.0|9084             |PENDING        |\n",
      "|25879   |2014-01-01 00:00:00.0|5118             |PENDING        |\n",
      "|25880   |2014-01-01 00:00:00.0|10146            |CANCELED       |\n",
      "|25881   |2014-01-01 00:00:00.0|3205             |PENDING_PAYMENT|\n",
      "|25882   |2014-01-01 00:00:00.0|4598             |COMPLETE       |\n",
      "|25883   |2014-01-01 00:00:00.0|11764            |PENDING        |\n",
      "|25884   |2014-01-01 00:00:00.0|7904             |PENDING_PAYMENT|\n",
      "|25885   |2014-01-01 00:00:00.0|7253             |PENDING        |\n",
      "+--------+---------------------+-----------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter\n",
    "orders \\\n",
    "    .filter(date_format(\"order_date\", \"yyyyMM\") == \"201401\") \\\n",
    "    .show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dec67a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|order_month|count|\n",
      "+-----------+-----+\n",
      "|201401     |5908 |\n",
      "|201405     |5467 |\n",
      "|201312     |5892 |\n",
      "|201310     |5335 |\n",
      "|201311     |6381 |\n",
      "|201307     |1533 |\n",
      "|201407     |4468 |\n",
      "|201403     |5778 |\n",
      "|201404     |5657 |\n",
      "|201402     |5635 |\n",
      "+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by\n",
    "orders. \\\n",
    "    groupBy(date_format('order_date', 'yyyyMM').alias('order_month')). \\\n",
    "    count(). \\\n",
    "    show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e9b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dummy dataframe for checking functions\n",
    "l = [(\"X\", )]\n",
    "\n",
    "df = spark.createDataFrame(l, \"dummy STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45a45ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dummy: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f0fe23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|dummy|\n",
      "+-----+\n",
      "|    X|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "302be6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|current date|\n",
      "+------------+\n",
      "|  2021-06-22|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use the dummy dataframe to get current date\n",
    "\n",
    "df.select(current_date().alias(\"current date\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f791de",
   "metadata": {},
   "source": [
    "##### collection of employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2076038",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees = [\n",
    "    (1, \"Scott\", \"Tiger\", 1000.0, \n",
    "      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n",
    "    ),\n",
    "     (2, \"Henry\", \"Ford\", 1250.0, \n",
    "      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "     ),\n",
    "     (3, \"Nick\", \"Junior\", 750.0, \n",
    "      \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n",
    "     ),\n",
    "     (4, \"Bill\", \"Gomes\", 1500.0, \n",
    "      \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n",
    "     )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8db9dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe\n",
    "\n",
    "employeesDF = spark.createDataFrame(employees, \"\"\"employee_id INT, first_name STRING, \n",
    "                    last_name STRING, salary FLOAT, nationality STRING,\n",
    "                    phone_number STRING, ssn STRING\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4977ca9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|nationality   |phone_number    |ssn        |\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|1          |Scott     |Tiger    |1000.0|united states |+1 123 456 7890 |123 45 6789|\n",
      "|2          |Henry     |Ford     |1250.0|India         |+91 234 567 8901|456 78 9123|\n",
      "|3          |Nick      |Junior   |750.0 |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|4          |Bill      |Gomes    |1500.0|AUSTRALIA     |+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44ead7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|   nationality|count|\n",
      "+--------------+-----+\n",
      "|         India|    1|\n",
      "|united KINGDOM|    1|\n",
      "| united states|    1|\n",
      "|     AUSTRALIA|    1|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    groupBy(\"nationality\"). \\\n",
    "    count(). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d89546a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    orderBy(\"employee_id\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eb44e6",
   "metadata": {},
   "source": [
    "##### Covert string type to column type\n",
    "\n",
    "Let's say we want to convert first name and last name to upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "629f0262",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JError",
     "evalue": "An error occurred while calling z:org.apache.spark.sql.functions.upper. Trace:\npy4j.Py4JException: Method upper([class java.lang.String]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:339)\n\tat py4j.Gateway.invoke(Gateway.java:276)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2502100d2a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0memployeesDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"last_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# This will fail as the upper function can be applied to columns, not string expressions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# notice the error: Method upper([class java.lang.String]) does not exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36m_\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n\u001b[1;32m    331\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m                     format(target_id, \".\", name, value))\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             raise Py4JError(\n",
      "\u001b[0;31mPy4JError\u001b[0m: An error occurred while calling z:org.apache.spark.sql.functions.upper. Trace:\npy4j.Py4JException: Method upper([class java.lang.String]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:339)\n\tat py4j.Gateway.invoke(Gateway.java:276)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n\n"
     ]
    }
   ],
   "source": [
    "employeesDF.select(upper(\"first_name\"), upper(\"last_name\")). \\\n",
    "    show()\n",
    "\n",
    "# This will fail as the upper function can be applied to columns, not string expressions\n",
    "# notice the error: Method upper([class java.lang.String]) does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95fa6985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+\n",
      "|upper(first_name)|upper(last_name)|\n",
      "+-----------------+----------------+\n",
      "|            SCOTT|           TIGER|\n",
      "|            HENRY|            FORD|\n",
      "|             NICK|          JUNIOR|\n",
      "|             BILL|           GOMES|\n",
      "+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF.select(upper(col(\"first_name\")), upper(col(\"last_name\"))). \\\n",
    "    show()\n",
    "\n",
    "# col() coverts string expression to column type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92682b8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'desc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-fd95955a04d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This will fail as the function desc is available only on column type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0memployeesDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0morderBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"employee_id\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'desc'"
     ]
    }
   ],
   "source": [
    "# This will fail as the function desc is available only on column type.\n",
    "employeesDF. \\\n",
    "    orderBy(\"employee_id\".desc()). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f6a4811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can invoke desc on columns which are of type column\n",
    "employeesDF. \\\n",
    "    orderBy(col(\"employee_id\").desc()). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5408a95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative - we can also refer column names using Data Frame like this\n",
    "employeesDF. \\\n",
    "    orderBy(upper(employeesDF['first_name']).alias('first_name')). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3612219c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "|          4|      Bill|    Gomes|1500.0|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "|          2|     Henry|     Ford|1250.0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          1|     Scott|    Tiger|1000.0| united states| +1 123 456 7890|123 45 6789|\n",
      "+-----------+----------+---------+------+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative - we can also refer column names using Data Frame like this\n",
    "employeesDF. \\\n",
    "    orderBy(upper(employeesDF.first_name).alias('first_name')). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d0032",
   "metadata": {},
   "source": [
    "##### * Extract last 4 digits from the phone number.\n",
    "\n",
    "##### * Extract last 4 digits from SSN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "266c2b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-----------+---------------------+---------------+\n",
      "|employee_id|phone_number    |ssn        |phone_num_last4digits|ssn_last4digits|\n",
      "+-----------+----------------+-----------+---------------------+---------------+\n",
      "|1          |+1 123 456 7890 |123 45 6789|7890                 |6789           |\n",
      "|2          |+91 234 567 8901|456 78 9123|8901                 |9123           |\n",
      "|3          |+44 111 111 1111|222 33 4444|1111                 |4444           |\n",
      "|4          |+61 987 654 3210|789 12 6118|3210                 |6118           |\n",
      "+-----------+----------------+-----------+---------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF. \\\n",
    "    select(\"employee_id\", \"phone_number\", \"ssn\"). \\\n",
    "    withColumn(\"phone_num_last4digits\", substring(col(\"phone_number\"), -4, 4)). \\\n",
    "    withColumn(\"ssn_last4digits\", substring(col(\"ssn\"), -4, 4)). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4746ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|split(Hello World, how are you,  )|\n",
      "+----------------------------------+\n",
      "|[Hello, World,, how, are, you]    |\n",
      "+----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df dummay dataframe\n",
    "\n",
    "df.select(split(lit(\"Hello World, how are you\"), \" \")). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d844497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|split(Hello World, how are you,  )[2]|\n",
      "+-------------------------------------+\n",
      "|how                                  |\n",
      "+-------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(split(lit(\"Hello World, how are you\"), \" \")[2]). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "888c3a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|word  |\n",
      "+------+\n",
      "|Hello |\n",
      "|World,|\n",
      "|how   |\n",
      "|are   |\n",
      "|you   |\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(explode(split(lit(\"Hello World, how are you\"), \" \")).alias('word')). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ce3e0",
   "metadata": {},
   "source": [
    "##### Create an employees dataframe with multiple phone numbers for each employee\n",
    "\n",
    "Now, count the number phone numbers each employee has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67c62003",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees2 = [(1, \"Scott\", \"Tiger\", 1000.0, \n",
    "                      \"united states\", \"+1 123 456 7890,+1 234 567 8901\", \"123 45 6789\"\n",
    "                     ),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, \n",
    "                      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "                     ),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, \n",
    "                      \"united KINGDOM\", \"+44 111 111 1111,+44 222 222 2222\", \"222 33 4444\"\n",
    "                     ),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, \n",
    "                      \"AUSTRALIA\", \"+61 987 654 3210,+61 876 543 2109\", \"789 12 6118\"\n",
    "                     )\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d304b387",
   "metadata": {},
   "outputs": [],
   "source": [
    "employeesDF2 = spark. \\\n",
    "    createDataFrame(employees2,\n",
    "                    schema=\"\"\"employee_id INT, first_name STRING, \n",
    "                    last_name STRING, salary FLOAT, nationality STRING,\n",
    "                    phone_numbers STRING, ssn STRING\"\"\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e93a29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------------------------+\n",
      "|employee_id|phone_numbers                    |\n",
      "+-----------+---------------------------------+\n",
      "|1          |+1 123 456 7890,+1 234 567 8901  |\n",
      "|2          |+91 234 567 8901                 |\n",
      "|3          |+44 111 111 1111,+44 222 222 2222|\n",
      "|4          |+61 987 654 3210,+61 876 543 2109|\n",
      "+-----------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF2. \\\n",
    "    select('employee_id', 'phone_numbers'). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4092c674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+\n",
      "|employee_id|number of phone numbers|\n",
      "+-----------+-----------------------+\n",
      "|1          |2                      |\n",
      "|3          |2                      |\n",
      "|4          |2                      |\n",
      "|2          |1                      |\n",
      "+-----------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF2. \\\n",
    "    select('employee_id', explode(split(col('phone_numbers'), \",\"))). \\\n",
    "    groupBy(\"employee_id\"). \\\n",
    "    count(). \\\n",
    "    select('employee_id', col(\"count\").alias(\"number of phone numbers\")). \\\n",
    "    show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebdc7e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(\"   Hello.    \",)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f170334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(l).toDF(\"dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cebf0b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|        dummy|\n",
      "+-------------+\n",
      "|   Hello.    |\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c75adea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+---------+------+\n",
      "|        dummy|     ltrim|    rtrim|  trim|\n",
      "+-------------+----------+---------+------+\n",
      "|   Hello.    |Hello.    |   Hello.|Hello.|\n",
      "+-------------+----------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn(\"ltrim\", ltrim(col(\"dummy\"))). \\\n",
    "  withColumn(\"rtrim\", rtrim(col(\"dummy\"))). \\\n",
    "  withColumn(\"trim\", trim(col(\"dummy\"))). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ddf72fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------+------+\n",
      "|        dummy|     ltrim|   rtrim|  trim|\n",
      "+-------------+----------+--------+------+\n",
      "|   Hello.    |Hello.    |   Hello|Hello.|\n",
      "+-------------+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# if we do not specify trimStr, it will be defaulted to space\n",
    "df2.withColumn(\"ltrim\", expr(\"ltrim(dummy)\")). \\\n",
    "  withColumn(\"rtrim\", expr(\"rtrim('.', rtrim(dummy))\")). \\\n",
    "  withColumn(\"trim\", trim(col(\"dummy\"))). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea953ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------+------+\n",
      "|        dummy|     ltrim|   rtrim|  trim|\n",
      "+-------------+----------+--------+------+\n",
      "|   Hello.    |Hello.    |   Hello|Hello.|\n",
      "+-------------+----------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn(\"ltrim\", expr(\"trim(LEADING ' ' FROM dummy)\")). \\\n",
    "  withColumn(\"rtrim\", expr(\"trim(TRAILING '.' FROM rtrim(dummy))\")). \\\n",
    "  withColumn(\"trim\", expr(\"trim(BOTH ' ' FROM dummy)\")). \\\n",
    "  show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514bf14c",
   "metadata": {},
   "source": [
    "#### Dealing with null values\n",
    "\n",
    "* We can use `coalesce` to return first non null value.\n",
    "\n",
    "* We also have traditional SQL style functions such as `nvl`. However, they can be used either with `expr` or `selectExpr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bccfc1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "employees2 = [(1, \"Scott\", \"Tiger\", 1000.0, 10,\n",
    "                      \"united states\", \"+1 123 456 7890\", \"123 45 6789\"\n",
    "                     ),\n",
    "                     (2, \"Henry\", \"Ford\", 1250.0, None,\n",
    "                      \"India\", \"+91 234 567 8901\", \"456 78 9123\"\n",
    "                     ),\n",
    "                     (3, \"Nick\", \"Junior\", 750.0, '',\n",
    "                      \"united KINGDOM\", \"+44 111 111 1111\", \"222 33 4444\"\n",
    "                     ),\n",
    "                     (4, \"Bill\", \"Gomes\", 1500.0, 10,\n",
    "                      \"AUSTRALIA\", \"+61 987 654 3210\", \"789 12 6118\"\n",
    "                     )\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c3c8559",
   "metadata": {},
   "outputs": [],
   "source": [
    "employeesDF2 = spark. \\\n",
    "    createDataFrame(employees2,\n",
    "                    schema=\"\"\"employee_id INT, first_name STRING, \n",
    "                    last_name STRING, salary FLOAT, bonus STRING, nationality STRING,\n",
    "                    phone_number STRING, ssn STRING\"\"\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d6d8bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF2.show()\n",
    "\n",
    "# Notice the bonus column\n",
    "# It has an empty string '' as well as null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dacd7171",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid argument, not a string or column: 0 of type <class 'int'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-3af105ef9b49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0memployeesDF2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bonus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bonus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# This will fail as 0 is not a column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/functions.py\u001b[0m in \u001b[0;36mcoalesce\u001b[0;34m(*cols)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \"\"\"\n\u001b[1;32m    346\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_to_java_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_to_seq\u001b[0;34m(sc, cols, converter)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark-2.4.7-bin-hadoop2.7/python/pyspark/sql/column.py\u001b[0m in \u001b[0;36m_to_java_column\u001b[0;34m(col)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;34m\"{0} of type {1}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;34m\"For column literals, use 'lit', 'array', 'struct' or 'create_map' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \"function.\".format(col, type(col)))\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mjcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid argument, not a string or column: 0 of type <class 'int'>. For column literals, use 'lit', 'array', 'struct' or 'create_map' function."
     ]
    }
   ],
   "source": [
    "# Replace the null with 0 using coalesce\n",
    "\n",
    "employeesDF2. \\\n",
    "    withColumn('bonus', coalesce('bonus', 0)). \\\n",
    "    show()\n",
    "# This will fail as 0 is not a column\n",
    "# Notice the error: not a string or column: 0 of type <class 'int'>. For column literals, use 'lit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "01133022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF2. \\\n",
    "    withColumn('bonus', coalesce(col('bonus'), lit(\"0\"))). \\\n",
    "    show()\n",
    "# null is replaced by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4253d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|    0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's replace the empty string '' by 0 using coalesce\n",
    "\n",
    "# Remember that, when we cast a column, if casting is not possible, the it returns null\n",
    "# similarly, if we cast the column bonus to int, the empty string '' won't be casted and will have null\n",
    "# which can be easily replaced by 0 using coalesce\n",
    "employeesDF2. \\\n",
    "    withColumn('bonus', coalesce(col('bonus').cast(\"int\"), lit(\"0\"))). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95fee3",
   "metadata": {},
   "source": [
    "##### Using nvl with expr/selectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd42b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace the null with 0, using nvl\n",
    "\n",
    "employeesDF2. \\\n",
    "    withColumn('bonus', expr(\"nvl(bonus, 0)\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4f04fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|    0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now let's replace the empty string '' by 0 using nvl and nullif\n",
    "# nullif(a, b) -> if a=b returns null, else returns a\n",
    "\n",
    "employeesDF2. \\\n",
    "    withColumn('bonus', expr(\"nvl(nullif(bonus, ''), 0)\")). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1e9a5",
   "metadata": {},
   "source": [
    "##### get updated salary: salary + salary * bonus /100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f5e2cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+--------------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|updated salary|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+--------------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|        1100.0|\n",
      "|          2|     Henry|     Ford|1250.0| null|         India|+91 234 567 8901|456 78 9123|        1250.0|\n",
      "|          3|      Nick|   Junior| 750.0|     |united KINGDOM|+44 111 111 1111|222 33 4444|         750.0|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|        1650.0|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF2. \\\n",
    "    withColumn('updated salary', col('salary') + (col('salary') * coalesce(col('bonus').cast('int'), lit(0)) / 100)). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af975c5",
   "metadata": {},
   "source": [
    "##### Update the bonus column using CASE WHEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e5c77efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|    0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF2. \\\n",
    "    withColumn('bonus', expr(\"\"\"CASE WHEN bonus IS NULL OR bonus = '' THEN 0\n",
    "                                ELSE bonus\n",
    "                                END\"\"\"\n",
    "                            )\n",
    "              ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "41dd8596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|employee_id|first_name|last_name|salary|bonus|   nationality|    phone_number|        ssn|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "|          1|     Scott|    Tiger|1000.0|   10| united states| +1 123 456 7890|123 45 6789|\n",
      "|          2|     Henry|     Ford|1250.0|    0|         India|+91 234 567 8901|456 78 9123|\n",
      "|          3|      Nick|   Junior| 750.0|    0|united KINGDOM|+44 111 111 1111|222 33 4444|\n",
      "|          4|      Bill|    Gomes|1500.0|   10|     AUSTRALIA|+61 987 654 3210|789 12 6118|\n",
      "+-----------+----------+---------+------+-----+--------------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employeesDF2. \\\n",
    "    withColumn(\n",
    "        'bonus',\n",
    "        when((col('bonus').isNull()) | (col('bonus') == lit('')), 0).otherwise(col('bonus'))\n",
    "    ). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af8c6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
