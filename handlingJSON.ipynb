{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263d8e6b",
   "metadata": {},
   "source": [
    "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameReader.json.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74f9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Data Processing - Overview'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327c2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "readComplexJSONDF = spark.read.option(\"multiLine\",\"true\").option(\"mode\", \"permissive\").json('complexJSON.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3920fcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nationality: string (nullable = true)\n",
      " |-- results: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- user: struct (nullable = true)\n",
      " |    |    |    |-- BSN: string (nullable = true)\n",
      " |    |    |    |-- cell: string (nullable = true)\n",
      " |    |    |    |-- dob: long (nullable = true)\n",
      " |    |    |    |-- email: string (nullable = true)\n",
      " |    |    |    |-- gender: string (nullable = true)\n",
      " |    |    |    |-- location: struct (nullable = true)\n",
      " |    |    |    |    |-- city: string (nullable = true)\n",
      " |    |    |    |    |-- state: string (nullable = true)\n",
      " |    |    |    |    |-- street: string (nullable = true)\n",
      " |    |    |    |    |-- zip: long (nullable = true)\n",
      " |    |    |    |-- md5: string (nullable = true)\n",
      " |    |    |    |-- name: struct (nullable = true)\n",
      " |    |    |    |    |-- first: string (nullable = true)\n",
      " |    |    |    |    |-- last: string (nullable = true)\n",
      " |    |    |    |    |-- title: string (nullable = true)\n",
      " |    |    |    |-- password: string (nullable = true)\n",
      " |    |    |    |-- phone: string (nullable = true)\n",
      " |    |    |    |-- picture: struct (nullable = true)\n",
      " |    |    |    |    |-- large: string (nullable = true)\n",
      " |    |    |    |    |-- medium: string (nullable = true)\n",
      " |    |    |    |    |-- thumbnail: string (nullable = true)\n",
      " |    |    |    |-- registered: long (nullable = true)\n",
      " |    |    |    |-- salt: string (nullable = true)\n",
      " |    |    |    |-- sha1: string (nullable = true)\n",
      " |    |    |    |-- sha256: string (nullable = true)\n",
      " |    |    |    |-- username: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "readComplexJSONDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e99235c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-------+\n",
      "|nationality|             results|version|\n",
      "+-----------+--------------------+-------+\n",
      "|         NL|[[[12059376, (727...|    0.8|\n",
      "+-----------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "readComplexJSONDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c11a35",
   "metadata": {},
   "source": [
    "the “results” tag is an array, so to read the content inside an array element we need to Explode it first. The below code will show how we can read Location and Name from the above input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac870982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------+-----+-------+-----+-----+\n",
      "|city  |state     |street       |zip  |first  |last |title|\n",
      "+------+----------+-------------+-----+-------+-----+-----+\n",
      "|gennep|overijssel|1510 vismarkt|35356|genelva|spits|ms   |\n",
      "+------+----------+-------------+-----+-------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explodeArrDF = readComplexJSONDF.withColumn('Exp_RESULTS', explode(col('results'))).drop('results')\n",
    "\n",
    "# Read location and name\n",
    "dfReadSpecificStructure = explodeArrDF.select(\"Exp_RESULTS.user.location.*\", \"Exp_RESULTS.user.name.*\")\n",
    "\n",
    "dfReadSpecificStructure.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb13e1",
   "metadata": {},
   "source": [
    "#### Read from HTTP link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8880dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----+\n",
      "|first    |last      |title|\n",
      "+---------+----------+-----+\n",
      "|maélie   |moulin    |mrs  |\n",
      "|florent  |rodriguez |mr   |\n",
      "|thiago   |caron     |mr   |\n",
      "|eva      |perrin    |ms   |\n",
      "|erwan    |rey       |mr   |\n",
      "|eloïse   |morel     |ms   |\n",
      "|bastien  |leroy     |mr   |\n",
      "|eva      |adam      |miss |\n",
      "|valentine|carpentier|ms   |\n",
      "|tessa    |le gall   |ms   |\n",
      "+---------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "\n",
    "# Online data source\n",
    "onlineData = 'https://randomuser.me/api/0.8/?results=10'\n",
    "\n",
    "# read the online data file\n",
    "httpData = urlopen(onlineData).read().decode('utf-8')\n",
    "\n",
    "# convert into RDD\n",
    "rdd = spark.sparkContext.parallelize([httpData])\n",
    "\n",
    "# create a Dataframe\n",
    "jsonDF = spark.read.json(rdd)\n",
    "\n",
    "# read all the users name:\n",
    "readUser = jsonDF.withColumn('Exp_Results', explode('results')).select('Exp_Results.user.name.*')\n",
    "readUser.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f3354",
   "metadata": {},
   "source": [
    "https://ch-nabarun.medium.com/read-json-using-pyspark-f792bda95741\n",
    "    \n",
    "https://sparkbyexamples.com/pyspark/pyspark-parse-json-from-string-column-text-file/    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24876e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawDF = spark.read.json(\"complexJSON2.json\", multiLine = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f971146b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+----+----+----+-----------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|batters                                                  |id  |name|ppu |topping                                                                                                                                  |type |\n",
      "+---------------------------------------------------------+----+----+----+-----------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|[[[1001, Regular], [1002, Chocolate], [1003, Blueberry]]]|0001|Cake|0.55|[[5001, None], [5002, Glazed], [5005, Sugar], [5007, Powdered Sugar], [5006, Chocolate with Sprinkles], [5003, Chocolate], [5004, Maple]]|donut|\n",
      "+---------------------------------------------------------+----+----+----+-----------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e91cc078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- batters: struct (nullable = true)\n",
      " |    |-- batter: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- ppu: double (nullable = true)\n",
      " |-- topping: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6c9fb",
   "metadata": {},
   "source": [
    "column batters is a struct of an array of a struct. Column topping is an array of a struct. Column id, name, ppu, and type are simple string, string, double, and string columns respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5858642",
   "metadata": {},
   "source": [
    "#### Convert Nested “batters” to Structured DataFrame\n",
    "\n",
    "First of all, let's rename the top-level “id” column because we have another “id” as a key of element struct under the batters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e030dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDF = rawDF.withColumnRenamed(\"id\", \"key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c481f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- batter: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batDF = sampleDF.select(\"key\", \"batters.batter\")\n",
    "\n",
    "batDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a345e79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------------------------------------------+\n",
      "|key |batter                                                 |\n",
      "+----+-------------------------------------------------------+\n",
      "|0001|[[1001, Regular], [1002, Chocolate], [1003, Blueberry]]|\n",
      "+----+-------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batDF.show(2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70843580",
   "metadata": {},
   "source": [
    "Let’s create a separate row for each element of “batter” array by exploding “batter” column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dc309d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "| key|       new_batter|\n",
      "+----+-----------------+\n",
      "|0001|  [1001, Regular]|\n",
      "|0001|[1002, Chocolate]|\n",
      "|0001|[1003, Blueberry]|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bat2DF = batDF.select(\"key\", explode(\"batter\").alias(\"new_batter\"))\n",
    "\n",
    "bat2DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2d07d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- new_batter: struct (nullable = true)\n",
      " |    |-- id: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bat2DF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb89a1d",
   "metadata": {},
   "source": [
    "Now we can extract the individual elements from the “new_batter” struct. We can use a dot (“.”) operator to extract the individual element or we can use “*” with dot (“.”) operator to select all the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73fe6122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+\n",
      "| key|  id|     type|\n",
      "+----+----+---------+\n",
      "|0001|1001|  Regular|\n",
      "|0001|1002|Chocolate|\n",
      "|0001|1003|Blueberry|\n",
      "+----+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bat2DF.select(\"key\", \"new_batter.*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036292d",
   "metadata": {},
   "source": [
    "Let’s put together everything we discussed so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c575684a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+---------+\n",
      "| key|bat_id| bat_type|\n",
      "+----+------+---------+\n",
      "|0001|  1001|  Regular|\n",
      "|0001|  1002|Chocolate|\n",
      "|0001|  1003|Blueberry|\n",
      "+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalBatDF = (sampleDF\n",
    "        .select(\"key\",  \n",
    "explode(\"batters.batter\").alias(\"new_batter\"))\n",
    "        .select(\"key\", \"new_batter.*\")\n",
    "        .withColumnRenamed(\"id\", \"bat_id\")\n",
    "        .withColumnRenamed(\"type\", \"bat_type\"))\n",
    "finalBatDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661945d8",
   "metadata": {},
   "source": [
    "#### Convert Nested “toppings” to Structured DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3831cb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- batters: struct (nullable = true)\n",
      " |    |-- batter: array (nullable = true)\n",
      " |    |    |-- element: struct (containsNull = true)\n",
      " |    |    |    |-- id: string (nullable = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |-- key: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- ppu: double (nullable = true)\n",
      " |-- topping: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampleDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f19aa105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------------------------+\n",
      "|key |top_id|top_type                |\n",
      "+----+------+------------------------+\n",
      "|0001|5001  |None                    |\n",
      "|0001|5002  |Glazed                  |\n",
      "|0001|5005  |Sugar                   |\n",
      "|0001|5007  |Powdered Sugar          |\n",
      "|0001|5006  |Chocolate with Sprinkles|\n",
      "|0001|5003  |Chocolate               |\n",
      "|0001|5004  |Maple                   |\n",
      "+----+------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topDF = (sampleDF\n",
    "        .select(\"key\", explode(\"topping\").alias(\"new_topping\"))\n",
    "        .select(\"key\", \"new_topping.*\")\n",
    "        .withColumnRenamed(\"id\", \"top_id\")\n",
    "        .withColumnRenamed(\"type\", \"top_type\")\n",
    "        )\n",
    "topDF.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e618e7",
   "metadata": {},
   "source": [
    "### PySpark JSON Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e352e24",
   "metadata": {},
   "source": [
    "#### from_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011b079",
   "metadata": {},
   "source": [
    "`from_json()` function is used to convert JSON string into Struct type or Map type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c25ee",
   "metadata": {},
   "source": [
    "`from_json(col, schema, options={})`\n",
    "\n",
    "Parses a column containing a JSON string into a `MapType` with `StringType` as keys type, `StructType` or `ArrayType` with the specified schema. \n",
    "\n",
    "Returns null, in the case of an unparseable string.\n",
    "\n",
    "__Parameters__ : ___col___ : Column or str, string column in json format\n",
    "\n",
    "__schema__ : DataType or str\n",
    "\n",
    "a StructType or ArrayType of StructType to use when parsing the json column.\n",
    "\n",
    "the DDL-formatted string is also supported for schema.\n",
    "\n",
    "__options__ : dict, optional\n",
    "\n",
    "options to control parsing. accepts the same options as the json datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7244f15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|key|   value|\n",
      "+---+--------+\n",
      "|  1|{\"a\": 1}|\n",
      "+---+--------+\n",
      "\n",
      "root\n",
      " |-- key: long (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "+----+\n",
      "|json|\n",
      "+----+\n",
      "| [1]|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1, '''{\"a\": 1}''')]\n",
    "\n",
    "schema = StructType([StructField(\"a\", IntegerType())])\n",
    "\n",
    "df = spark.createDataFrame(data, (\"key\", \"value\"))\n",
    "\n",
    "df.show()\n",
    "df.printSchema()\n",
    "\n",
    "df.select(from_json(df.value, schema).alias(\"json\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bacabcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|json|\n",
      "+----+\n",
      "| [1]|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(from_json(df.value, \"a INT\").alias(\"json\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e145b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = ArrayType(StructType([StructField(\"a\", IntegerType())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b46de8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| json|\n",
      "+-----+\n",
      "|[[1]]|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(from_json(df.value, schema).alias(\"json\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fa3449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------+\n",
      "|id |value                                                                     |\n",
      "+---+--------------------------------------------------------------------------+\n",
      "|1  |{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n",
      "+---+--------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "jsonString=\"\"\"{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}\"\"\"\n",
    "\n",
    "df=spark.createDataFrame([(1,jsonString)],[\"id\",\"value\"])\n",
    "\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2ff6d9",
   "metadata": {},
   "source": [
    "#### covert to MapType using `from_json()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f7bdbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- value: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+---+---------------------------------------------------------------------------+\n",
      "|id |value                                                                      |\n",
      "+---+---------------------------------------------------------------------------+\n",
      "|1  |[Zipcode -> 704, ZipCodeType -> STANDARD, City -> PARC PARQUE, State -> PR]|\n",
      "+---+---------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2=df.withColumn(\"value\",from_json(df.value, MapType(StringType(), StringType() ) ) )\n",
    "\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ddc7ec",
   "metadata": {},
   "source": [
    "#### covert to StructType using `from_json()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06d0cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema = StructType[\n",
    "#     (StructField(\"key\", StringType())), \n",
    "#     (StructField(\"value\", StringType()))]\n",
    "\n",
    "# df3=df.withColumn(\"value\",from_json(df.value, schema))\n",
    "\n",
    "# df3.printSchema()\n",
    "# df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15741dc7",
   "metadata": {},
   "source": [
    "#### to_json()\n",
    "\n",
    "`to_json()` function is used to convert DataFrame columns MapType or Struct type to JSON string. Throws an exception, in the case of an unsupported type.\n",
    "\n",
    "`to_json(col, options={})`\n",
    "\n",
    "__Parameters__ : __col__ : Column or str, name of column containing a struct, an array or a map.\n",
    "\n",
    "__options__ : dict, optional\n",
    "options to control converting. accepts the same options as the JSON datasource. Additionally the function supports the pretty option which enables pretty JSON generation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9150795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------------------------------------------------------------------+\n",
      "|id |value                                                                      |\n",
      "+---+---------------------------------------------------------------------------+\n",
      "|1  |[Zipcode -> 704, ZipCodeType -> STANDARD, City -> PARC PARQUE, State -> PR]|\n",
      "+---+---------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5110835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------------------------------------------------+\n",
      "|id |value                                                                       |\n",
      "+---+----------------------------------------------------------------------------+\n",
      "|1  |{\"Zipcode\":\"704\",\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n",
      "+---+----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.withColumn(\"value\",to_json(col(\"value\"))) \\\n",
    "   .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3979a0dc",
   "metadata": {},
   "source": [
    "#### json_tuple()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82563573",
   "metadata": {},
   "source": [
    "Function `json_tuple()` is used the query or extract the elements from JSON column and create the result as a new columns.\n",
    "\n",
    "Creates a new row for a json column according to the given field names.\n",
    "\n",
    "`json_tuple(col, *fields)`\n",
    "\n",
    "__Parameters__ : __col__ : Column or str, string column in json format\n",
    "\n",
    "__fieldsstr__ : fields to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e76313d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------+\n",
      "|id |value                                                                     |\n",
      "+---+--------------------------------------------------------------------------+\n",
      "|1  |{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n",
      "+---+--------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0056cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----------+-----------+\n",
      "|id |Zipcode|ZipCodeType|City       |\n",
      "+---+-------+-----------+-----------+\n",
      "|1  |704    |STANDARD   |PARC PARQUE|\n",
      "+---+-------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"id\"),json_tuple(col(\"value\"), \"Zipcode\", \"ZipCodeType\", \"City\")) \\\n",
    "    .toDF(\"id\",\"Zipcode\",\"ZipCodeType\",\"City\") \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850d9e38",
   "metadata": {},
   "source": [
    "#### get_json_object()\n",
    "\n",
    "`get_json_object()` extracts json object from a json string based on json path specified, and returns json string of the extracted json object. It will return null if the input json string is invalid.\n",
    "\n",
    "__Parameters__ : __col__ : Column or str, string column in json format\n",
    "\n",
    "__pathstr__ : path to the json object to extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2dca625d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------+\n",
      "|id |value                                                                     |\n",
      "+---+--------------------------------------------------------------------------+\n",
      "|1  |{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}|\n",
      "+---+--------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45207f26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-----+\n",
      "|id |ZipCodeType|State|\n",
      "+---+-----------+-----+\n",
      "|1  |STANDARD   |PR   |\n",
      "+---+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"id\"), get_json_object(col(\"value\"),\"$.ZipCodeType\").alias(\"ZipCodeType\")\n",
    "                   , get_json_object(col(\"value\"), \"$.State\").alias(\"State\")) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a592bdfa",
   "metadata": {},
   "source": [
    "#### schema_of_json()\n",
    "\n",
    "`schema_of_json()` Parses a JSON string and infers its schema in DDL format.\n",
    "\n",
    "`schema_of_json(json, options={})`\n",
    "\n",
    "__Parameters__: __json__ : Column or str, a JSON string or a foldable string column containing a JSON string.\n",
    "\n",
    "__options__ : dict, optional, options to control parsing. accepts the same options as the JSON datasource. Changed in version 3.0: It accepts options parameter to control schema inferring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8bba109e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "struct<City:string,State:string,ZipCodeType:string,Zipcode:bigint>\n"
     ]
    }
   ],
   "source": [
    "schemaStr=spark.range(1) \\\n",
    "    .select(schema_of_json(lit(\"\"\"{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}\"\"\"))) \\\n",
    "    .collect()[0][0]\n",
    "print(schemaStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa4720c",
   "metadata": {},
   "source": [
    "#### parse or read a JSON string from a TEXT/CSV file and convert it into DataFrame\n",
    "\n",
    "parse a JSON string from a text file and convert it to PySpark DataFrame columns using `from_json()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09c194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
