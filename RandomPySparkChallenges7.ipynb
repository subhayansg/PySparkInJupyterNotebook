{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a08fa983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Data Processing - Overview'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff36ccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f74fc0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(101, 'xyz', 10),\n",
    "(102, 'xyz', 10),\n",
    "(103, 'xyz', 40),\n",
    "(104, 'pqr', 40),\n",
    "(105, 'pqr', 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6ea928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(data, ['id', 'city', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd48e4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+\n",
      "| id|city|age|\n",
      "+---+----+---+\n",
      "|101| xyz| 10|\n",
      "|102| xyz| 10|\n",
      "|103| xyz| 40|\n",
      "|104| pqr| 40|\n",
      "|105| pqr| 60|\n",
      "+---+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ae58e",
   "metadata": {},
   "source": [
    "___Find the ids of people whose age is greater than avg_age per city___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30e855e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.createOrReplaceTempView(\"tab1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f205685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.sql(\"SELECT id FROM (SELECT id, age, AVG(age) OVER(PARTITION BY city) AS avg_age FROM tab1) WHERE age > avg_age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf827202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|105|\n",
      "|103|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae2e9f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+-------+\n",
      "| id|city|age|avg_age|\n",
      "+---+----+---+-------+\n",
      "|104| pqr| 40|   50.0|\n",
      "|105| pqr| 60|   50.0|\n",
      "|103| xyz| 40|   20.0|\n",
      "|101| xyz| 10|   20.0|\n",
      "|102| xyz| 10|   20.0|\n",
      "+---+----+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(\"city\")\n",
    "\n",
    "df3 = df1.withColumn(\"avg_age\", avg(\"age\").over(windowSpec))\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c453694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|105|\n",
      "|103|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = df3.filter(\"age > avg_age\"). \\\n",
    "    select(\"id\")\n",
    "\n",
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b135531",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = [(2020, 10, 2000),\n",
    "(2021, 10, 1000),\n",
    "(2022, 20, 2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d8fd0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = spark.createDataFrame(data2, ['year', 'stock_purchse', 'profit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38b5c948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+------+\n",
      "|year|stock_purchse|profit|\n",
      "+----+-------------+------+\n",
      "|2020|           10|  2000|\n",
      "|2021|           10|  1000|\n",
      "|2022|           20|  2000|\n",
      "+----+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13346f67",
   "metadata": {},
   "source": [
    "___Find the year where previous year profit is more than current year profit___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7c69f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.createOrReplaceTempView(\"t1\")\n",
    "\n",
    "df6 = spark.sql(\"SELECT year FROM (SELECT year, \\\n",
    "profit, LAG(profit, 1) OVER(ORDER BY YEAR) AS prev_year_prof FROM t1) WHERE prev_year_prof > profit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "249e1527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2021|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17523710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2021|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df7 = spark.sql(\"SELECT year FROM (SELECT year, \\\n",
    "profit, LAG(profit, 1) OVER(ORDER BY YEAR DESC) AS prev_year_prof FROM t1) WHERE prev_year_prof > profit\")\n",
    "\n",
    "df7.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e16d4de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+------+--------------+\n",
      "|year|stock_purchse|profit|prev_year_prof|\n",
      "+----+-------------+------+--------------+\n",
      "|2020|           10|  2000|          null|\n",
      "|2021|           10|  1000|          2000|\n",
      "|2022|           20|  2000|          1000|\n",
      "+----+-------------+------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "win_spec = Window.orderBy(\"year\")\n",
    "df8 = df5.withColumn(\"prev_year_prof\", lag(\"profit\", 1).over(win_spec))\n",
    "\n",
    "df8.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42904bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------+------+\n",
      "|year|stock_purchse|profit|\n",
      "+----+-------------+------+\n",
      "|2021|           10|  1000|\n",
      "+----+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df9 = df8.filter(\"prev_year_prof > profit\").drop(\"prev_year_prof\")\n",
    "\n",
    "df9.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4e64f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = [(2020, 1, 100),\n",
    "(2020, 2, 110),\n",
    "(2020, 5, 150),\n",
    "(2020, 3, 90),\n",
    "(2020, 8, 130),\n",
    "(2021, 2, 150),\n",
    "(2021, 5, 90),\n",
    "(2021, 7, 130)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43e89e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|year|month|profit|\n",
      "+----+-----+------+\n",
      "|2020|    1|   100|\n",
      "|2020|    2|   110|\n",
      "|2020|    5|   150|\n",
      "|2020|    3|    90|\n",
      "|2020|    8|   130|\n",
      "|2021|    2|   150|\n",
      "|2021|    5|    90|\n",
      "|2021|    7|   130|\n",
      "+----+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df10 = spark.createDataFrame(data3, ['year', 'month', 'profit'])\n",
    "\n",
    "df10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12763870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
