{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef2cc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Data Processing - Overview'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf726c",
   "metadata": {},
   "source": [
    "#### PySpark MapType\n",
    "\n",
    "PySpark MapType is used to represent map key-value pair similar to python Dictionary (Dict), it takes two mandatory arguments `keyType` and `valueType` of type DataType and one optional boolean argument `valueContainsNull`. keyType and valueType can be any type that extends the DataType class. for e.g StringType, IntegerType, ArrayType, MapType, StructType (struct) e.t.c.\n",
    "\n",
    "* The First param keyType is used to specify the type of the key in the map.\n",
    "* The Second param valueType is used to specify the type of the value in the map.\n",
    "* Third parm valueContainsNull is an optional boolean type that is used to specify if the value of the second param can accept Null/None values.\n",
    "* The key of the map won’t accept None/Null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5094640f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+----------+-----------------------------+\n",
      "|name      |properties                   |\n",
      "+----------+-----------------------------+\n",
      "|James     |[eye -> brown, hair -> black]|\n",
      "|Michael   |[eye ->, hair -> brown]      |\n",
      "|Robert    |[eye -> black, hair -> red]  |\n",
      "|Washington|[eye -> grey, hair -> grey]  |\n",
      "|Jefferson |[eye -> , hair -> brown]     |\n",
      "+----------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField('name', StringType(), True),\n",
    "    StructField('properties', MapType(StringType(),StringType()),True)\n",
    "])\n",
    "\n",
    "#create a DataFrame by using above StructType schema\n",
    "dataDictionary = [\n",
    "        ('James',{'hair':'black','eye':'brown'}),\n",
    "        ('Michael',{'hair':'brown','eye':None}),\n",
    "        ('Robert',{'hair':'red','eye':'black'}),\n",
    "        ('Washington',{'hair':'grey','eye':'grey'}),\n",
    "        ('Jefferson',{'hair':'brown','eye':''})\n",
    "        ]\n",
    "df1 = spark.createDataFrame(data=dataDictionary, schema = schema)\n",
    "df1.printSchema()\n",
    "df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666859ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- hair: string (nullable = true)\n",
      " |-- eye: string (nullable = true)\n",
      "\n",
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df1.rdd.map(lambda x: (x.name, x.properties[\"hair\"], x.properties[\"eye\"])) \\\n",
    "      .toDF([\"name\",\"hair\",\"eye\"])\n",
    "\n",
    "df2.printSchema()\n",
    "\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a015d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n",
      "+----------+-----+-----+\n",
      "|      name| hair|  eye|\n",
      "+----------+-----+-----+\n",
      "|     James|black|brown|\n",
      "|   Michael|brown| null|\n",
      "|    Robert|  red|black|\n",
      "|Washington| grey| grey|\n",
      "| Jefferson|brown|     |\n",
      "+----------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.withColumn(\"hair\",df1.properties.getItem(\"hair\")) \\\n",
    "  .withColumn(\"eye\",df1.properties.getItem(\"eye\")) \\\n",
    "  .drop(\"properties\") \\\n",
    "  .show()\n",
    "\n",
    "df1.withColumn(\"hair\",df1.properties[\"hair\"]) \\\n",
    "  .withColumn(\"eye\",df1.properties[\"eye\"]) \\\n",
    "  .drop(\"properties\") \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b2d737",
   "metadata": {},
   "source": [
    "## MapType Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ac191",
   "metadata": {},
   "source": [
    "___explode(col)___\n",
    "\n",
    "Returns a new row for each element in the given array or map. Uses the __default column name col for elements in the array__ and __key and value for elements in the map__ unless specified otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca19b21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+\n",
      "|      name| key|value|\n",
      "+----------+----+-----+\n",
      "|     James| eye|brown|\n",
      "|     James|hair|black|\n",
      "|   Michael| eye| null|\n",
      "|   Michael|hair|brown|\n",
      "|    Robert| eye|black|\n",
      "|    Robert|hair|  red|\n",
      "|Washington| eye| grey|\n",
      "|Washington|hair| grey|\n",
      "| Jefferson| eye|     |\n",
      "| Jefferson|hair|brown|\n",
      "+----------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(df1.name,explode(df1.properties)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af67dd1",
   "metadata": {},
   "source": [
    "___map_keys() – Get All Map Keys___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f6e368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|      name|map_keys(properties)|\n",
      "+----------+--------------------+\n",
      "|     James|         [eye, hair]|\n",
      "|   Michael|         [eye, hair]|\n",
      "|    Robert|         [eye, hair]|\n",
      "|Washington|         [eye, hair]|\n",
      "| Jefferson|         [eye, hair]|\n",
      "+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(df1.name,map_keys(df1.properties)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349e09e",
   "metadata": {},
   "source": [
    "___In case if you wanted to get all map keys as Python List.___ \n",
    "#### WARNING: This runs very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb54863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| col|\n",
      "+----+\n",
      "| eye|\n",
      "|hair|\n",
      "+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['eye', 'hair']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keysDf = df1.select(explode(map_keys(df1.properties))).distinct()\n",
    "\n",
    "keysDf.show()\n",
    "\n",
    "keysDf.rdd.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b351e",
   "metadata": {},
   "source": [
    "___map_values() – Get All map Values___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd78bb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------+\n",
      "|      name|map_values(properties)|\n",
      "+----------+----------------------+\n",
      "|     James|        [brown, black]|\n",
      "|   Michael|             [, brown]|\n",
      "|    Robert|          [black, red]|\n",
      "|Washington|          [grey, grey]|\n",
      "| Jefferson|             [, brown]|\n",
      "+----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select(\"name\", map_values(df1.properties)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2b8da2",
   "metadata": {},
   "source": [
    "___map_concat()___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e274e07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|map3                    |\n",
      "+------------------------+\n",
      "|[1 -> a, 2 -> b, 3 -> c]|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT map(1, 'a', 2, 'b') as map1, map(3, 'c') as map2\")\n",
    "\n",
    "df.select(map_concat(\"map1\", \"map2\").alias(\"map3\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda10504",
   "metadata": {},
   "source": [
    "### Q1.\n",
    "Input data\n",
    "```\n",
    "-------------------------\n",
    "| Brand | type |  amount|\n",
    "-------------------------\n",
    "|  B   |   a  |   10   |\n",
    "|  B   |   b  |   20   |\n",
    "|  C   |   c  |   30   |\n",
    "-------------------------\n",
    "```\n",
    "Output data\n",
    "```\n",
    "-------------------------\n",
    "| Brand | MAP_type_AMOUNT \n",
    "-------------------------\n",
    "|  B    | {a: 10, b:20} |\n",
    "|  C    | {c: 30}       |\n",
    "-------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab00b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('B', 'a', 10),\n",
    "       ('B', 'b', 20),\n",
    "       ('C', 'c', 30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a671e296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+\n",
      "|Brand|type|amount|\n",
      "+-----+----+------+\n",
      "|    B|   a|    10|\n",
      "|    B|   b|    20|\n",
      "|    C|   c|    30|\n",
      "+-----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = spark.createDataFrame(data, ['Brand', 'type', 'amount'])\n",
    "\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9b627ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Brand|   MAP_type_AMOUNT|\n",
      "+-----+------------------+\n",
      "|    B|[[a, 10], [b, 20]]|\n",
      "|    C|         [[c, 30]]|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_converted1 = df3.groupBy(\"Brand\"). \\\n",
    "    agg(collect_list(struct(col(\"Type\"), col(\"Amount\"))).alias(\"MAP_type_AMOUNT\"))\n",
    "\n",
    "df_converted1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f882b658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------+\n",
      "|Brand|  type|  amount|\n",
      "+-----+------+--------+\n",
      "|    B|[b, a]|[20, 10]|\n",
      "|    C|   [c]|    [30]|\n",
      "+-----+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_converted21 = (\n",
    "    df3.groupBy('Brand')\n",
    "    .agg(\n",
    "        collect_list('type').alias('type'),\n",
    "        collect_list('amount').alias('amount'),\n",
    "    )\n",
    ")\n",
    "\n",
    "df_converted21.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b417d831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Brand|   MAP_type_AMOUNT|\n",
      "+-----+------------------+\n",
      "|    B|[a -> 10, b -> 20]|\n",
      "|    C|         [c -> 30]|\n",
      "+-----+------------------+\n",
      "\n",
      "root\n",
      " |-- Brand: string (nullable = true)\n",
      " |-- MAP_type_AMOUNT: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: long (valueContainsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_converted2 = (\n",
    "    df3.groupBy('Brand')\n",
    "    .agg(\n",
    "        collect_list('type').alias('type'),\n",
    "        collect_list('amount').alias('amount'),\n",
    "    )\n",
    "    .withColumn('MAP_type_AMOUNT', map_from_arrays('type', 'amount'))\n",
    "    .drop('type', 'amount')\n",
    ")\n",
    "\n",
    "df_converted2.show()\n",
    "\n",
    "df_converted2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9caa71b",
   "metadata": {},
   "source": [
    "## Array functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b7a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = [(\"x\", 4, 1),\n",
    "  (\"x\", 6, 2),\n",
    "  (\"z\", 7, 3),\n",
    "  (\"a\", 3, 4),\n",
    "  (\"z\", 5, 2),\n",
    "  (\"x\", 7, 3),\n",
    "  (\"x\", 9, 7),\n",
    "  (\"z\", 1, 8),\n",
    "  (\"z\", 4, 9),\n",
    "  (\"z\", 7, 4),\n",
    "  (\"a\", 8, 5),\n",
    "  (\"a\", 5, 2),\n",
    "  (\"a\", 3, 8),\n",
    "  (\"x\", 2, 7),\n",
    "  (\"z\", 1, 9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a82eaa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|col1|col2|col3|\n",
      "+----+----+----+\n",
      "|   x|   4|   1|\n",
      "|   x|   6|   2|\n",
      "|   z|   7|   3|\n",
      "|   a|   3|   4|\n",
      "|   z|   5|   2|\n",
      "|   x|   7|   3|\n",
      "|   x|   9|   7|\n",
      "|   z|   1|   8|\n",
      "|   z|   4|   9|\n",
      "|   z|   7|   4|\n",
      "|   a|   8|   5|\n",
      "|   a|   5|   2|\n",
      "|   a|   3|   8|\n",
      "|   x|   2|   7|\n",
      "|   z|   1|   9|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_df = spark.createDataFrame(d1, [\"col1\", \"col2\", \"col3\"])\n",
    "\n",
    "initial_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee828548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "|col1|        array_col1|        array_col2|\n",
      "+----+------------------+------------------+\n",
      "|   x|   [4, 6, 7, 9, 2]|   [1, 2, 3, 7, 7]|\n",
      "|   z|[1, 4, 7, 1, 7, 5]|[8, 9, 4, 9, 3, 2]|\n",
      "|   a|      [8, 5, 3, 3]|      [5, 2, 8, 4]|\n",
      "+----+------------------+------------------+\n",
      "\n",
      "root\n",
      " |-- col1: string (nullable = true)\n",
      " |-- array_col1: array (nullable = true)\n",
      " |    |-- element: long (containsNull = false)\n",
      " |-- array_col2: array (nullable = true)\n",
      " |    |-- element: long (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_df = initial_df.groupBy(\"col1\") \\\n",
    "               .agg(collect_list(\"col2\").alias(\"array_col1\"),\n",
    "                    collect_list(\"col3\").alias(\"array_col2\"))\n",
    "\n",
    "full_df.show()\n",
    "\n",
    "full_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73732b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|col1|        array_col2|\n",
      "+----+------------------+\n",
      "|   x|   [7, 1, 2, 3, 7]|\n",
      "|   z|[8, 9, 4, 9, 3, 2]|\n",
      "|   a|      [4, 5, 2, 8]|\n",
      "+----+------------------+\n",
      "\n",
      "root\n",
      " |-- col1: string (nullable = true)\n",
      " |-- array_col2: array (nullable = true)\n",
      " |    |-- element: long (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4 = full_df.drop(\"array_col1\")\n",
    "\n",
    "df4.show()\n",
    "\n",
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d430942",
   "metadata": {},
   "source": [
    "___array_contains()___\n",
    "\n",
    "If we need to find a particular element is present in array, we can use array_contains function.\n",
    "\n",
    "This function returns true if the value is present in array and false otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c6fb4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------+\n",
      "|col1|        array_col2|result|\n",
      "+----+------------------+------+\n",
      "|   x|   [1, 2, 3, 7, 7]|  true|\n",
      "|   z|[3, 2, 8, 9, 4, 9]|  true|\n",
      "|   a|      [4, 5, 2, 8]| false|\n",
      "+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_contains_df = df4.withColumn(\"result\", array_contains(\"array_col2\", 3))\n",
    "\n",
    "arr_contains_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfeaeaf",
   "metadata": {},
   "source": [
    "___array_distinct___\n",
    "\n",
    "This function returns only distinct values from an array and removes duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d23d8800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+---------------+\n",
      "|col1|        array_col2|         result|\n",
      "+----+------------------+---------------+\n",
      "|   x|   [7, 1, 2, 3, 7]|   [7, 1, 2, 3]|\n",
      "|   z|[3, 2, 8, 9, 4, 9]|[3, 2, 8, 9, 4]|\n",
      "|   a|      [4, 5, 2, 8]|   [4, 5, 2, 8]|\n",
      "+----+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_distinct_df = df4.withColumn(\"result\", array_distinct(\"array_col2\"))\n",
    "\n",
    "arr_distinct_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c540c56",
   "metadata": {},
   "source": [
    "___array_except___\n",
    "\n",
    "This function returns the elements from first array which are not present in second array. This is logically equivalent to set subtract operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15529984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+---------+\n",
      "|col1|        array_col1|        array_col2|   result|\n",
      "+----+------------------+------------------+---------+\n",
      "|   x|   [4, 6, 7, 9, 2]|   [1, 2, 3, 7, 7]|[4, 6, 9]|\n",
      "|   z|[1, 4, 7, 1, 7, 5]|[8, 9, 4, 9, 3, 2]|[1, 7, 5]|\n",
      "|   a|      [3, 8, 5, 3]|      [4, 5, 2, 8]|      [3]|\n",
      "+----+------------------+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_except_df = full_df.withColumn(\"result\", array_except(\"array_col1\", \"array_col2\"))\n",
    "\n",
    "arr_except_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b470e91e",
   "metadata": {},
   "source": [
    "___array_intersect___\n",
    "\n",
    "This function returns common elements from both arrays. This is logically equivalent to set intersection operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c074eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+------+\n",
      "|col1|        array_col1|        array_col2|result|\n",
      "+----+------------------+------------------+------+\n",
      "|   x|   [4, 6, 7, 9, 2]|   [1, 2, 3, 7, 7]|[7, 2]|\n",
      "|   z|[1, 4, 7, 1, 7, 5]|[8, 9, 4, 9, 3, 2]|   [4]|\n",
      "|   a|      [3, 8, 5, 3]|      [4, 5, 2, 8]|[8, 5]|\n",
      "+----+------------------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_intersect_df = full_df.withColumn(\"result\", array_intersect(\"array_col1\", \"array_col2\"))\n",
    "\n",
    "arr_intersect_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4efa6",
   "metadata": {},
   "source": [
    "___array_join___\n",
    "\n",
    "This Function joins all the array elements based on delimiter defined as the second argument.\n",
    "\n",
    "Note: if there are any null values then we can replace with third argument (`nullReplacement`) with any string value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61286cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+-----------+\n",
      "|col1|        array_col2|     result|\n",
      "+----+------------------+-----------+\n",
      "|   x|   [7, 1, 2, 3, 7]|  7,1,2,3,7|\n",
      "|   z|[8, 9, 4, 9, 3, 2]|8,9,4,9,3,2|\n",
      "|   a|      [4, 5, 2, 8]|    4,5,2,8|\n",
      "+----+------------------+-----------+\n",
      "\n",
      "root\n",
      " |-- col1: string (nullable = true)\n",
      " |-- array_col2: array (nullable = true)\n",
      " |    |-- element: long (containsNull = false)\n",
      " |-- result: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_join_df = df4.withColumn(\"result\", array_join(\"array_col2\", \",\"))\n",
    "\n",
    "arr_join_df.show()\n",
    "\n",
    "arr_join_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c96dc12",
   "metadata": {},
   "source": [
    "___array_max___\n",
    "\n",
    "This function returns the maximum value from an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b223dd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------+\n",
      "|col1|        array_col2|result|\n",
      "+----+------------------+------+\n",
      "|   x|   [1, 2, 3, 7, 7]|     7|\n",
      "|   z|[3, 2, 8, 9, 4, 9]|     9|\n",
      "|   a|      [5, 2, 8, 4]|     8|\n",
      "+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_max_df = df4.withColumn(\"result\", array_max(\"array_col2\"))\n",
    "\n",
    "arr_max_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab27996",
   "metadata": {},
   "source": [
    "___array_min___\n",
    "\n",
    "This function returns the minimum value from an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f40a0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------+\n",
      "|col1|        array_col2|result|\n",
      "+----+------------------+------+\n",
      "|   x|   [7, 1, 2, 3, 7]|     1|\n",
      "|   z|[8, 9, 4, 9, 3, 2]|     2|\n",
      "|   a|      [5, 2, 8, 4]|     2|\n",
      "+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_min_df = df4.withColumn(\"result\", array_min(\"array_col2\"))\n",
    "\n",
    "arr_min_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb52292",
   "metadata": {},
   "source": [
    "___array_position___\n",
    "\n",
    "This function returns the position of first occurrence of a specified element. If the element is not present it returns 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e21750d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------+\n",
      "|col1|        array_col2|result|\n",
      "+----+------------------+------+\n",
      "|   x|   [1, 2, 3, 7, 7]|     4|\n",
      "|   z|[8, 9, 4, 9, 3, 2]|     0|\n",
      "|   a|      [4, 5, 2, 8]|     0|\n",
      "+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_pos_df = df4.withColumn(\"result\", array_position(\"array_col2\", 7))\n",
    "\n",
    "arr_pos_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed495f31",
   "metadata": {},
   "source": [
    "___array_remove___\n",
    "\n",
    "This function removes all the occurrences of an element from an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db291df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "|col1|        array_col2|            result|\n",
      "+----+------------------+------------------+\n",
      "|   x|   [7, 1, 2, 3, 7]|         [1, 2, 3]|\n",
      "|   z|[8, 9, 4, 9, 3, 2]|[8, 9, 4, 9, 3, 2]|\n",
      "|   a|      [5, 2, 8, 4]|      [5, 2, 8, 4]|\n",
      "+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_remove_df = df4.withColumn(\"result\", array_remove(\"array_col2\", 7))\n",
    "\n",
    "arr_remove_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60cb5e",
   "metadata": {},
   "source": [
    "___array_repeat___\n",
    "\n",
    "This function creates an array that is repeated as specified by second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17351c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+----------------------------------------+\n",
      "|col1|array_col2        |result                                  |\n",
      "+----+------------------+----------------------------------------+\n",
      "|x   |[7, 1, 2, 3, 7]   |[[7, 1, 2, 3, 7], [7, 1, 2, 3, 7]]      |\n",
      "|z   |[3, 2, 8, 9, 4, 9]|[[3, 2, 8, 9, 4, 9], [3, 2, 8, 9, 4, 9]]|\n",
      "|a   |[4, 5, 2, 8]      |[[4, 5, 2, 8], [4, 5, 2, 8]]            |\n",
      "+----+------------------+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_repeat_df = df4.withColumn(\"result\", array_repeat(\"array_col2\", 2))\n",
    "\n",
    "arr_repeat_df.show(truncate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576ec38c",
   "metadata": {},
   "source": [
    "___array_sort___\n",
    "\n",
    "This function sorts the elements of an array in `ascending` order. Nulls will be placed at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bdcf0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "|col1|        array_col2|            result|\n",
      "+----+------------------+------------------+\n",
      "|   x|   [7, 1, 2, 3, 7]|   [1, 2, 3, 7, 7]|\n",
      "|   z|[8, 9, 4, 9, 3, 2]|[2, 3, 4, 8, 9, 9]|\n",
      "|   a|      [4, 5, 2, 8]|      [2, 4, 5, 8]|\n",
      "+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_sort_df = df4.withColumn(\"result\", array_sort(\"array_col2\"))\n",
    "\n",
    "arr_sort_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d2e04",
   "metadata": {},
   "source": [
    "___array_union___\n",
    "\n",
    "This function returns the union of all elements from the input arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a5affcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+------------------------+\n",
      "|col1|array_col1        |array_col2        |result                  |\n",
      "+----+------------------+------------------+------------------------+\n",
      "|x   |[2, 4, 6, 7, 9]   |[7, 1, 2, 3, 7]   |[2, 4, 6, 7, 9, 1, 3]   |\n",
      "|z   |[1, 4, 7, 1, 7, 5]|[8, 9, 4, 9, 3, 2]|[1, 4, 7, 5, 8, 9, 3, 2]|\n",
      "|a   |[3, 8, 5, 3]      |[4, 5, 2, 8]      |[3, 8, 5, 4, 2]         |\n",
      "+----+------------------+------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_union_df = full_df.withColumn(\"result\", array_union(\"array_col1\", \"array_col2\"))\n",
    "\n",
    "arr_union_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb083d9",
   "metadata": {},
   "source": [
    "___arrays_overlap___\n",
    "\n",
    "This function checks if at least one element is common/overlapping in arrays. \n",
    "\n",
    "It returns true if at least one element is common in both array and false otherwise. It returns null if at least one of the arrays is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75250fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+------+\n",
      "|col1|        array_col1|        array_col2|result|\n",
      "+----+------------------+------------------+------+\n",
      "|   x|   [4, 6, 7, 9, 2]|   [1, 2, 3, 7, 7]|  true|\n",
      "|   z|[7, 5, 1, 4, 7, 1]|[3, 2, 8, 9, 4, 9]|  true|\n",
      "|   a|      [8, 5, 3, 3]|      [5, 2, 8, 4]|  true|\n",
      "+----+------------------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_overlap_df = full_df.withColumn(\"result\", arrays_overlap(\"array_col1\", \"array_col2\"))\n",
    "\n",
    "arr_overlap_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fb697e",
   "metadata": {},
   "source": [
    "___arrays_zip___\n",
    "\n",
    "This function merges the i-th element of an array and returns array<struct>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e49925c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------------+----------------------------------------------+\n",
      "|array_col1        |new_array_col  |result                                        |\n",
      "+------------------+---------------+----------------------------------------------+\n",
      "|[2, 4, 6, 7, 9]   |[7, 1, 3, 7]   |[[2, 7], [4, 1], [6, 3], [7, 7], [9,]]        |\n",
      "|[7, 5, 1, 4, 7, 1]|[3, 8, 9, 4, 9]|[[7, 3], [5, 8], [1, 9], [4, 4], [7, 9], [1,]]|\n",
      "|[8, 5, 3, 3]      |[5, 8, 4]      |[[8, 5], [5, 8], [3, 4], [3,]]                |\n",
      "+------------------+---------------+----------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove element \"2\" from array column \"array_col2\"\n",
    "temp_df = full_df.withColumn(\"new_array_col\", array_remove(\"array_col2\",2))\n",
    "\n",
    "# zip column \"array_col1\" with newly created column \"new_array_col\"\n",
    "arr_zip_df = temp_df.withColumn(\"result\", arrays_zip(\"array_col1\", \"new_array_col\")).select(\"array_col1\", \"new_array_col\", \"result\")\n",
    "\n",
    "arr_zip_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4918b6e3",
   "metadata": {},
   "source": [
    "___concat___\n",
    "\n",
    "This function concatenates all the elements of both arrays into a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "900f9820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+------------------------------------+\n",
      "|col1|array_col1        |array_col2        |result                              |\n",
      "+----+------------------+------------------+------------------------------------+\n",
      "|x   |[2, 4, 6, 7, 9]   |[7, 1, 2, 3, 7]   |[2, 4, 6, 7, 9, 7, 1, 2, 3, 7]      |\n",
      "|z   |[1, 4, 7, 1, 7, 5]|[8, 9, 4, 9, 3, 2]|[1, 4, 7, 1, 7, 5, 8, 9, 4, 9, 3, 2]|\n",
      "|a   |[3, 8, 5, 3]      |[4, 5, 2, 8]      |[3, 8, 5, 3, 4, 5, 2, 8]            |\n",
      "+----+------------------+------------------+------------------------------------+\n",
      "\n",
      "root\n",
      " |-- col1: string (nullable = true)\n",
      " |-- array_col1: array (nullable = true)\n",
      " |    |-- element: long (containsNull = false)\n",
      " |-- array_col2: array (nullable = true)\n",
      " |    |-- element: long (containsNull = false)\n",
      " |-- result: array (nullable = true)\n",
      " |    |-- element: long (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_cat_df = full_df.withColumn(\"result\", concat(\"array_col1\", \"array_col2\"))\n",
    "\n",
    "arr_cat_df.show(truncate=False)\n",
    "\n",
    "arr_cat_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79684c",
   "metadata": {},
   "source": [
    "___element_at___\n",
    "\n",
    "This function returns the element at a specified index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2444e6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------+\n",
      "|col1|        array_col2|result|\n",
      "+----+------------------+------+\n",
      "|   x|   [1, 2, 3, 7, 7]|     1|\n",
      "|   z|[3, 2, 8, 9, 4, 9]|     3|\n",
      "|   a|      [5, 2, 8, 4]|     5|\n",
      "+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_element_at_df = df4.withColumn(\"result\", element_at(\"array_col2\", 1))\n",
    "\n",
    "arr_element_at_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc486d1",
   "metadata": {},
   "source": [
    "___flatten___\n",
    "\n",
    "This function returns a single array from array of an arrays. \n",
    "\n",
    "If an array is more than 2 levels deep, it removes one level of nesting from an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8febace6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+------------------------------------+\n",
      "|repeat                                  |result                              |\n",
      "+----------------------------------------+------------------------------------+\n",
      "|[[7, 1, 2, 3, 7], [7, 1, 2, 3, 7]]      |[7, 1, 2, 3, 7, 7, 1, 2, 3, 7]      |\n",
      "|[[3, 2, 8, 9, 4, 9], [3, 2, 8, 9, 4, 9]]|[3, 2, 8, 9, 4, 9, 3, 2, 8, 9, 4, 9]|\n",
      "|[[5, 2, 8, 4], [5, 2, 8, 4]]            |[5, 2, 8, 4, 5, 2, 8, 4]            |\n",
      "+----------------------------------------+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate the nested array using the function \"array_repeat\".\n",
    "arr_repeat_df1 = df4.withColumn(\"repeat\", array_repeat(\"array_col2\", 2))\n",
    "\n",
    "# flatten the nested array.\n",
    "arr_flat_df1 = arr_repeat_df1.withColumn(\"result\", flatten(\"repeat\")).select(\"repeat\", \"result\")\n",
    "\n",
    "arr_flat_df1.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833dc114",
   "metadata": {},
   "source": [
    "___map_from_arrays___\n",
    "\n",
    "This function creates a map column. _Elements of the first column will be used for keys and second column will be used for values_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6003f476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "|col1|        array_col1|        array_col2|\n",
      "+----+------------------+------------------+\n",
      "|   x|   [2, 4, 6, 7, 9]|   [7, 1, 2, 3, 7]|\n",
      "|   z|[7, 5, 1, 4, 7, 1]|[3, 2, 8, 9, 4, 9]|\n",
      "|   a|      [3, 8, 5, 3]|      [4, 5, 2, 8]|\n",
      "+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "17f48c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------+---------------+\n",
      "|col1|     array_col1|     array_col2|\n",
      "+----+---------------+---------------+\n",
      "|   x|[4, 6, 7, 9, 2]|[1, 2, 3, 7, 7]|\n",
      "+----+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# remove duplicate keys from the dataframe, else job will fail\n",
    "upd_full_df = full_df.filter(\"col1 = 'x'\")\n",
    "\n",
    "upd_full_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd0b8521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+----------------------------------------+\n",
      "|array_col1     |array_col2     |result                                  |\n",
      "+---------------+---------------+----------------------------------------+\n",
      "|[4, 6, 7, 9, 2]|[1, 2, 3, 7, 7]|[4 -> 1, 6 -> 2, 7 -> 3, 9 -> 7, 2 -> 7]|\n",
      "+---------------+---------------+----------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "map_from_arr_df = upd_full_df.withColumn(\"result\", map_from_arrays(\"array_col1\", \"array_col2\")).drop(\"col1\")\n",
    "\n",
    "map_from_arr_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb5de0",
   "metadata": {},
   "source": [
    "___reverse___\n",
    "\n",
    "This function reverses the order of elements in input array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67469e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "|col1|        array_col2|            result|\n",
      "+----+------------------+------------------+\n",
      "|   x|   [1, 2, 3, 7, 7]|   [7, 7, 3, 2, 1]|\n",
      "|   z|[3, 2, 8, 9, 4, 9]|[9, 4, 9, 8, 2, 3]|\n",
      "|   a|      [4, 5, 2, 8]|      [8, 2, 5, 4]|\n",
      "+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_reverse_df = df4.withColumn(\"result\", reverse(\"array_col2\"))\n",
    "\n",
    "arr_reverse_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1df8567",
   "metadata": {},
   "source": [
    "__size__\n",
    "\n",
    "This function returns a number of elements in an array or map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d767833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------+\n",
      "|col1|        array_col2|result|\n",
      "+----+------------------+------+\n",
      "|   x|   [7, 1, 2, 3, 7]|     5|\n",
      "|   z|[8, 9, 4, 9, 3, 2]|     6|\n",
      "|   a|      [5, 2, 8, 4]|     4|\n",
      "+----+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_size_df = df4.withColumn(\"result\", size(\"array_col2\"))\n",
    "\n",
    "arr_size_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1f8ff",
   "metadata": {},
   "source": [
    "___shuffle___\n",
    "\n",
    "This function shuffles the elements of array randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c146d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "|col1|        array_col2|            result|\n",
      "+----+------------------+------------------+\n",
      "|   x|   [7, 1, 2, 3, 7]|   [3, 7, 7, 2, 1]|\n",
      "|   z|[3, 2, 8, 9, 4, 9]|[4, 9, 3, 8, 9, 2]|\n",
      "|   a|      [5, 2, 8, 4]|      [4, 8, 5, 2]|\n",
      "+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_shuffle_df = df4.withColumn(\"result\", shuffle(\"array_col2\"))\n",
    "\n",
    "arr_shuffle_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9cddfb",
   "metadata": {},
   "source": [
    "___slice___\n",
    "\n",
    "This function slices the array into a sub-array. We can specify the start of the index as second argument and number of elements as third argument.\n",
    "\n",
    "__Note__: Arrays in spark start with index 1. It also supports negative indexing to access the elements from last.\n",
    "\n",
    "Let’s try to create a sub-array of 3 elements starting from index 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aba43228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+---------+\n",
      "|col1|        array_col2|   result|\n",
      "+----+------------------+---------+\n",
      "|   x|   [1, 2, 3, 7, 7]|[2, 3, 7]|\n",
      "|   z|[8, 9, 4, 9, 3, 2]|[9, 4, 9]|\n",
      "|   a|      [5, 2, 8, 4]|[2, 8, 4]|\n",
      "+----+------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_slice_df = df4.withColumn(\"result\", slice(\"array_col2\", 2, 3))\n",
    "\n",
    "arr_slice_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f6bddf",
   "metadata": {},
   "source": [
    "___sort_array___\n",
    "\n",
    "This function sorts the array in ascending order by default. However, we can sort in __descending order__ with second arg as __asc=False__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ea180e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "|col1|        array_col2|            result|\n",
      "+----+------------------+------------------+\n",
      "|   x|   [1, 2, 3, 7, 7]|   [7, 7, 3, 2, 1]|\n",
      "|   z|[8, 9, 4, 9, 3, 2]|[9, 9, 8, 4, 3, 2]|\n",
      "|   a|      [5, 2, 8, 4]|      [8, 5, 4, 2]|\n",
      "+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_sort_df = df4.withColumn(\"result\", sort_array(\"array_col2\", asc=False))\n",
    "\n",
    "arr_sort_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608cb4e0",
   "metadata": {},
   "source": [
    "___explode___\n",
    "\n",
    "With array type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83495812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+\n",
      "|col1|slice_col|\n",
      "+----+---------+\n",
      "|   x|   [7, 1]|\n",
      "|   z|   [3, 2]|\n",
      "|   a|   [4, 5]|\n",
      "+----+---------+\n",
      "\n",
      "+----+---------+------+\n",
      "|col1|slice_col|result|\n",
      "+----+---------+------+\n",
      "|   x|   [1, 2]|     1|\n",
      "|   x|   [1, 2]|     2|\n",
      "|   z|   [3, 2]|     3|\n",
      "|   z|   [3, 2]|     2|\n",
      "|   a|   [4, 5]|     4|\n",
      "|   a|   [4, 5]|     5|\n",
      "+----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df = df4.withColumn(\"slice_col\", slice(\"array_col2\", 1, 2)) \\\n",
    "              .drop(\"array_col2\")\n",
    "\n",
    "temp_df.show()\n",
    "\n",
    "arr_explode_df = temp_df.withColumn(\"result\", explode(\"slice_col\"))\n",
    "\n",
    "arr_explode_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca331919",
   "metadata": {},
   "source": [
    "___posexplode___\n",
    "\n",
    "This function creates a new row for each element with position of an array or map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eec9f184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---+---+\n",
      "|col1|slice_col|pos|col|\n",
      "+----+---------+---+---+\n",
      "|x   |[1, 2]   |0  |1  |\n",
      "|x   |[1, 2]   |1  |2  |\n",
      "|z   |[3, 2]   |0  |3  |\n",
      "|z   |[3, 2]   |1  |2  |\n",
      "|a   |[5, 2]   |0  |5  |\n",
      "|a   |[5, 2]   |1  |2  |\n",
      "+----+---------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arr_posexplode_df = temp_df.select(\"*\", posexplode(\"slice_col\"))\n",
    "\n",
    "arr_posexplode_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a74f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
